# AIæ™ºèƒ½ä½“å¼€å‘æœ€ä½³å®è·µæŒ‡å—

> åŸºäº30+ä¸ªå¼€æºæ™ºèƒ½ä½“æ¡†æ¶æ·±åº¦åˆ†æçš„æœ€ä½³å®è·µæ€»ç»“

## ğŸ“‹ ç›®å½•

1. [å¼€å‘æœ€ä½³å®è·µ](#å¼€å‘æœ€ä½³å®è·µ)
2. [æ¶æ„è®¾è®¡åŸåˆ™](#æ¶æ„è®¾è®¡åŸåˆ™)
3. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
4. [å®‰å…¨é˜²æŠ¤æªæ–½](#å®‰å…¨é˜²æŠ¤æªæ–½)
5. [éƒ¨ç½²è¿ç»´æŒ‡å—](#éƒ¨ç½²è¿ç»´æŒ‡å—)
6. [æµ‹è¯•è´¨é‡ä¿è¯](#æµ‹è¯•è´¨é‡ä¿è¯)
7. [ç›‘æ§å‘Šè­¦ä½“ç³»](#ç›‘æ§å‘Šè­¦ä½“ç³»)

---

## å¼€å‘æœ€ä½³å®è·µ

### âœ… 1. æ¨¡å—åŒ–è®¾è®¡

**åŸåˆ™ï¼š**
- å°†æ™ºèƒ½ä½“åŠŸèƒ½æ‹†åˆ†ä¸ºç‹¬ç«‹æ¨¡å—
- ä½¿ç”¨æ¥å£å’ŒæŠ½è±¡ç±»å®šä¹‰æ ‡å‡†
- ä¿æŒæ¨¡å—é—´çš„æ¾è€¦åˆ

**å®ç°ç¤ºä¾‹ï¼š**
```python
from abc import ABC, abstractmethod

class MemoryInterface(ABC):
    """è®°å¿†æ¥å£å®šä¹‰"""
    
    @abstractmethod
    async def store(self, key: str, value: Any) -> bool:
        pass
    
    @abstractmethod
    async def retrieve(self, key: str) -> Any:
        pass

class ShortTermMemory(MemoryInterface):
    """çŸ­æœŸè®°å¿†å®ç°"""
    
    async def store(self, key: str, value: Any) -> bool:
        # å®ç°çŸ­æœŸè®°å¿†å­˜å‚¨
        pass
    
    async def retrieve(self, key: str) -> Any:
        # å®ç°çŸ­æœŸè®°å¿†æ£€ç´¢
        pass
```

### âœ… 2. é”™è¯¯å¤„ç†æœºåˆ¶

**ç­–ç•¥ï¼š**
- å®ç°å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- æä¾›ä¼˜é›…çš„é™çº§ç­–ç•¥
- è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—

**å®ç°ç¤ºä¾‹ï¼š**
```python
import logging
from typing import Optional

class AgentError(Exception):
    """æ™ºèƒ½ä½“åŸºç¡€å¼‚å¸¸"""
    pass

class ToolExecutionError(AgentError):
    """å·¥å…·æ‰§è¡Œå¼‚å¸¸"""
    pass

async def safe_tool_execution(tool_name: str, **kwargs) -> Optional[Any]:
    """å®‰å…¨çš„å·¥å…·æ‰§è¡Œ"""
    try:
        result = await tool_manager.execute_tool(tool_name, **kwargs)
        return result
    except ToolExecutionError as e:
        logger.error(f"Tool execution failed: {e}")
        # é™çº§ç­–ç•¥
        return await fallback_execution(tool_name, **kwargs)
    except Exception as e:
        logger.critical(f"Unexpected error: {e}")
        raise AgentError(f"Tool execution failed: {e}")
```

### âœ… 3. é…ç½®ç®¡ç†

**åŸåˆ™ï¼š**
- ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿä¿¡æ¯
- å®ç°é…ç½®çƒ­æ›´æ–°
- åˆ†ç¦»å¼€å‘å’Œç”Ÿäº§é…ç½®

**å®ç°ç¤ºä¾‹ï¼š**
```python
from pydantic_settings import BaseSettings
from typing import Optional

class AgentSettings(BaseSettings):
    """æ™ºèƒ½ä½“é…ç½®"""
    
    # åŸºç¡€é…ç½®
    agent_name: str = "MyAgent"
    version: str = "1.0.0"
    
    # APIé…ç½®
    openai_api_key: str
    anthropic_api_key: Optional[str] = None
    
    # æ•°æ®åº“é…ç½®
    database_url: str
    redis_url: str = "redis://localhost:6379"
    
    # å®‰å…¨é…ç½®
    max_iterations: int = 10
    timeout: int = 300
    rate_limit: int = 100
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# ä½¿ç”¨é…ç½®
settings = AgentSettings()
```

### âœ… 4. æ—¥å¿—è®°å½•

**ç­–ç•¥ï¼š**
- ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
- å®ç°æ—¥å¿—è½®è½¬
- åŒºåˆ†ä¸åŒçº§åˆ«çš„æ—¥å¿—

**å®ç°ç¤ºä¾‹ï¼š**
```python
import structlog
import logging
from datetime import datetime

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# ä½¿ç”¨ç¤ºä¾‹
async def process_task(task_id: str, input_data: str):
    logger.info("Processing task", task_id=task_id, input_length=len(input_data))
    
    try:
        result = await agent.process(input_data)
        logger.info("Task completed", task_id=task_id, success=True)
        return result
    except Exception as e:
        logger.error("Task failed", task_id=task_id, error=str(e), exc_info=True)
        raise
```

---

## æ¶æ„è®¾è®¡åŸåˆ™

### ğŸ—ï¸ 1. å•ä¸€èŒè´£åŸåˆ™

**æ¯ä¸ªæ¨¡å—åªè´Ÿè´£ä¸€ä¸ªåŠŸèƒ½ï¼š**

```python
class TaskPlanner:
    """ä»»åŠ¡è§„åˆ’å™¨ - åªè´Ÿè´£ä»»åŠ¡åˆ†è§£å’Œè§„åˆ’"""
    
    async def decompose_task(self, task: str) -> List[SubTask]:
        pass
    
    async def prioritize_tasks(self, tasks: List[SubTask]) -> List[SubTask]:
        pass

class MemoryManager:
    """è®°å¿†ç®¡ç†å™¨ - åªè´Ÿè´£è®°å¿†å­˜å‚¨å’Œæ£€ç´¢"""
    
    async def store_memory(self, key: str, value: Any) -> bool:
        pass
    
    async def retrieve_memory(self, key: str) -> Any:
        pass
```

### ğŸ—ï¸ 2. å¼€é—­åŸåˆ™

**å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å…³é—­ï¼š**

```python
class ToolRegistry:
    """å·¥å…·æ³¨å†Œå™¨ - æ”¯æŒåŠ¨æ€æ³¨å†Œæ–°å·¥å…·"""
    
    def __init__(self):
        self._tools = {}
    
    def register_tool(self, tool: Tool):
        """æ³¨å†Œæ–°å·¥å…·è€Œä¸ä¿®æ”¹ç°æœ‰ä»£ç """
        self._tools[tool.name] = tool
    
    def get_tool(self, name: str) -> Optional[Tool]:
        return self._tools.get(name)

# æ‰©å±•æ–°å·¥å…·
class CustomTool(Tool):
    def execute(self, **kwargs):
        # æ–°å·¥å…·å®ç°
        pass

# æ³¨å†Œæ–°å·¥å…·
registry.register_tool(CustomTool())
```

### ğŸ—ï¸ 3. ä¾èµ–å€’ç½®åŸåˆ™

**ä¾èµ–æŠ½è±¡è€Œä¸æ˜¯å…·ä½“å®ç°ï¼š**

```python
from abc import ABC, abstractmethod

class LLMProvider(ABC):
    """LLMæä¾›è€…æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def generate(self, prompt: str) -> str:
        pass

class OpenAIProvider(LLMProvider):
    """OpenAIå®ç°"""
    
    async def generate(self, prompt: str) -> str:
        # OpenAI APIè°ƒç”¨
        pass

class AnthropicProvider(LLMProvider):
    """Anthropicå®ç°"""
    
    async def generate(self, prompt: str) -> str:
        # Anthropic APIè°ƒç”¨
        pass

class Agent:
    """æ™ºèƒ½ä½“ä¾èµ–æŠ½è±¡æ¥å£"""
    
    def __init__(self, llm_provider: LLMProvider):
        self.llm_provider = llm_provider  # ä¾èµ–æŠ½è±¡
```

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### âš¡ 1. å¼‚æ­¥ç¼–ç¨‹

**ä½¿ç”¨å¼‚æ­¥I/Oæé«˜å¹¶å‘æ€§èƒ½ï¼š**

```python
import asyncio
import aiohttp
from typing import List

async def parallel_tool_execution(tools: List[Tool], inputs: List[str]) -> List[Any]:
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·"""
    
    async def execute_tool(tool: Tool, input_data: str) -> Any:
        return await tool.execute(input_data)
    
    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·
    tasks = [execute_tool(tool, input_data) for tool, input_data in zip(tools, inputs)]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    tools = [calculator_tool, search_tool, file_tool]
    inputs = ["2+2", "AI agents", "read file.txt"]
    
    results = await parallel_tool_execution(tools, inputs)
    print(results)
```

### âš¡ 2. ç¼“å­˜æœºåˆ¶

**å®ç°æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—ï¼š**

```python
import redis
import json
from typing import Any, Optional
import hashlib

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.default_ttl = 3600  # 1å°æ—¶
    
    def _generate_key(self, prefix: str, data: Any) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        data_str = json.dumps(data, sort_keys=True)
        hash_obj = hashlib.md5(data_str.encode())
        return f"{prefix}:{hash_obj.hexdigest()}"
    
    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        try:
            value = self.redis.get(key)
            return json.loads(value) if value else None
        except Exception as e:
            logger.warning(f"Cache get failed: {e}")
            return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """è®¾ç½®ç¼“å­˜"""
        try:
            ttl = ttl or self.default_ttl
            self.redis.setex(key, ttl, json.dumps(value))
            return True
        except Exception as e:
            logger.warning(f"Cache set failed: {e}")
            return False
    
    async def cached_execution(self, func, *args, **kwargs) -> Any:
        """ç¼“å­˜å‡½æ•°æ‰§è¡Œç»“æœ"""
        cache_key = self._generate_key(func.__name__, (args, kwargs))
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_result = await self.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
        result = await func(*args, **kwargs)
        await self.set(cache_key, result)
        
        return result
```

### âš¡ 3. è¿æ¥æ± ç®¡ç†

**ä½¿ç”¨è¿æ¥æ± æé«˜æ•°æ®åº“æ€§èƒ½ï¼š**

```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
import asyncpg
import aioredis

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, database_url: str):
        # PostgreSQLè¿æ¥æ± 
        self.pg_pool = None
        self.pg_url = database_url
        
        # Redisè¿æ¥æ± 
        self.redis_pool = None
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        # PostgreSQLè¿æ¥æ± 
        self.pg_pool = await asyncpg.create_pool(
            self.pg_url,
            min_size=5,
            max_size=20,
            command_timeout=60
        )
        
        # Redisè¿æ¥æ± 
        self.redis_pool = await aioredis.create_redis_pool(
            'redis://localhost:6379',
            minsize=5,
            maxsize=20
        )
    
    async def execute_query(self, query: str, *args) -> List[dict]:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        async with self.pg_pool.acquire() as conn:
            rows = await conn.fetch(query, *args)
            return [dict(row) for row in rows]
    
    async def cache_set(self, key: str, value: str, ttl: int = 3600):
        """è®¾ç½®Redisç¼“å­˜"""
        await self.redis_pool.setex(key, ttl, value)
    
    async def cache_get(self, key: str) -> Optional[str]:
        """è·å–Redisç¼“å­˜"""
        return await self.redis_pool.get(key)
```

---

## å®‰å…¨é˜²æŠ¤æªæ–½

### ğŸ›¡ï¸ 1. è¾“å…¥éªŒè¯

**å®ç°ä¸¥æ ¼çš„è¾“å…¥éªŒè¯ï¼š**

```python
import re
from typing import Any
from pydantic import BaseModel, validator

class TaskInput(BaseModel):
    """ä»»åŠ¡è¾“å…¥éªŒè¯æ¨¡å‹"""
    
    task_description: str
    priority: int
    context: dict
    
    @validator('task_description')
    def validate_task_description(cls, v):
        if len(v) > 10000:
            raise ValueError('Task description too long')
        
        # æ£€æŸ¥æ¶æ„æ¨¡å¼
        malicious_patterns = [
            r'<script.*?>.*?</script>',
            r'eval\s*\(',
            r'exec\s*\(',
            r'__import__\s*\(',
        ]
        
        for pattern in malicious_patterns:
            if re.search(pattern, v, re.IGNORECASE):
                raise ValueError(f'Malicious pattern detected: {pattern}')
        
        return v
    
    @validator('priority')
    def validate_priority(cls, v):
        if not 1 <= v <= 10:
            raise ValueError('Priority must be between 1 and 10')
        return v

# ä½¿ç”¨éªŒè¯
async def process_task_input(input_data: dict) -> TaskInput:
    """å¤„ç†å¹¶éªŒè¯ä»»åŠ¡è¾“å…¥"""
    try:
        validated_input = TaskInput(**input_data)
        return validated_input
    except Exception as e:
        logger.warning(f"Input validation failed: {e}")
        raise ValueError(f"Invalid input: {e}")
```

### ğŸ›¡ï¸ 2. æƒé™æ§åˆ¶

**å®ç°ç»†ç²’åº¦æƒé™æ§åˆ¶ï¼š**

```python
from enum import Enum
from typing import Set, Dict, Any

class Permission(Enum):
    """æƒé™æšä¸¾"""
    READ_MEMORY = "read_memory"
    WRITE_MEMORY = "write_memory"
    EXECUTE_TOOLS = "execute_tools"
    ACCESS_FILES = "access_files"
    NETWORK_ACCESS = "network_access"

class Role:
    """è§’è‰²å®šä¹‰"""
    
    def __init__(self, name: str, permissions: Set[Permission]):
        self.name = name
        self.permissions = permissions

class SecurityManager:
    """å®‰å…¨ç®¡ç†å™¨"""
    
    def __init__(self):
        self.roles = {
            "admin": Role("admin", set(Permission)),
            "user": Role("user", {Permission.READ_MEMORY, Permission.EXECUTE_TOOLS}),
            "guest": Role("guest", {Permission.READ_MEMORY}),
        }
        self.user_roles: Dict[str, str] = {}
    
    def assign_role(self, user_id: str, role_name: str):
        """åˆ†é…è§’è‰²"""
        if role_name not in self.roles:
            raise ValueError(f"Role {role_name} not found")
        self.user_roles[user_id] = role_name
    
    def check_permission(self, user_id: str, permission: Permission) -> bool:
        """æ£€æŸ¥æƒé™"""
        user_role = self.user_roles.get(user_id)
        if not user_role:
            return False
        
        role = self.roles[user_role]
        return permission in role.permissions
    
    async def authorize_action(self, user_id: str, action: str, **kwargs) -> bool:
        """æˆæƒæ“ä½œ"""
        permission_map = {
            "read_memory": Permission.READ_MEMORY,
            "write_memory": Permission.WRITE_MEMORY,
            "execute_tool": Permission.EXECUTE_TOOLS,
            "access_file": Permission.ACCESS_FILES,
            "network_request": Permission.NETWORK_ACCESS,
        }
        
        permission = permission_map.get(action)
        if not permission:
            return False
        
        return self.check_permission(user_id, permission)
```

### ğŸ›¡ï¸ 3. å®‰å…¨æŠ¤æ 

**å®ç°å¤šå±‚å®‰å…¨æŠ¤æ ï¼š**

```python
class SecurityGuardrail:
    """å®‰å…¨æŠ¤æ """
    
    def __init__(self):
        self.content_filters = [
            self._filter_toxic_content,
            self._filter_personal_info,
            self._filter_sensitive_data,
        ]
    
    async def validate_output(self, output: str) -> tuple[bool, str]:
        """éªŒè¯è¾“å‡ºå†…å®¹"""
        for filter_func in self.content_filters:
            is_safe, message = await filter_func(output)
            if not is_safe:
                return False, message
        
        return True, "Content is safe"
    
    async def _filter_toxic_content(self, content: str) -> tuple[bool, str]:
        """è¿‡æ»¤æœ‰æ¯’å†…å®¹"""
        toxic_keywords = ["hate", "violence", "harassment"]
        
        content_lower = content.lower()
        for keyword in toxic_keywords:
            if keyword in content_lower:
                return False, f"Toxic content detected: {keyword}"
        
        return True, "No toxic content"
    
    async def _filter_personal_info(self, content: str) -> tuple[bool, str]:
        """è¿‡æ»¤ä¸ªäººä¿¡æ¯"""
        import re
        
        # æ£€æŸ¥é‚®ç®±
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        if re.search(email_pattern, content):
            return False, "Personal email detected"
        
        # æ£€æŸ¥ç”µè¯å·ç 
        phone_pattern = r'\b\d{3}-\d{3}-\d{4}\b'
        if re.search(phone_pattern, content):
            return False, "Phone number detected"
        
        return True, "No personal info"
    
    async def _filter_sensitive_data(self, content: str) -> tuple[bool, str]:
        """è¿‡æ»¤æ•æ„Ÿæ•°æ®"""
        sensitive_patterns = [
            r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b',  # ä¿¡ç”¨å¡å·
            r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
        ]
        
        for pattern in sensitive_patterns:
            if re.search(pattern, content):
                return False, "Sensitive data detected"
        
        return True, "No sensitive data"
```

---

## éƒ¨ç½²è¿ç»´æŒ‡å—

### ğŸš€ 1. å®¹å™¨åŒ–éƒ¨ç½²

**ä½¿ç”¨Dockerè¿›è¡Œåº”ç”¨å®¹å™¨åŒ–ï¼š**

```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°
FROM python:3.11-slim as builder

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

FROM python:3.11-slim

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r agent && useradd -r -g agent agent

WORKDIR /app

# ä»builderé˜¶æ®µå¤åˆ¶ä¾èµ–
COPY --from=builder /root/.local /home/agent/.local
COPY --chown=agent:agent . .

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER agent

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PATH=/home/agent/.local/bin:$PATH
ENV PYTHONPATH=/app

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

EXPOSE 8000

CMD ["python", "main.py"]
```

### ğŸš€ 2. Kuberneteséƒ¨ç½²

**ä½¿ç”¨Kubernetesè¿›è¡Œå®¹å™¨ç¼–æ’ï¼š**

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-deployment
  labels:
    app: agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent
  template:
    metadata:
      labels:
        app: agent
    spec:
      containers:
      - name: agent
        image: agent:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: agent-secrets
              key: database-url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: agent-secrets
              key: openai-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: agent-service
spec:
  selector:
    app: agent
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: agent-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### ğŸš€ 3. CI/CDæµæ°´çº¿

**ä½¿ç”¨GitHub Actionså®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼š**

```yaml
# .github/workflows/deploy.yml
name: Deploy Agent

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: |
        pytest --cov=src tests/
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t agent:${{ github.sha }} .
        docker tag agent:${{ github.sha }} agent:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push agent:${{ github.sha }}
        docker push agent:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/
        kubectl rollout restart deployment/agent-deployment
```

---

## æµ‹è¯•è´¨é‡ä¿è¯

### ğŸ§ª 1. å•å…ƒæµ‹è¯•

**ç¼–å†™å…¨é¢çš„å•å…ƒæµ‹è¯•ï¼š**

```python
import pytest
import asyncio
from unittest.mock import Mock, AsyncMock
from agent_template import Agent, TaskPlanner, MemoryManager

class TestTaskPlanner:
    """ä»»åŠ¡è§„åˆ’å™¨æµ‹è¯•"""
    
    @pytest.fixture
    def planner(self):
        return TaskPlanner()
    
    @pytest.mark.asyncio
    async def test_decompose_task(self, planner):
        """æµ‹è¯•ä»»åŠ¡åˆ†è§£"""
        task_description = "Analyze market trends"
        tasks = await planner.decompose_task(task_description)
        
        assert len(tasks) == 4
        assert all(task.description for task in tasks)
        assert all(task.priority > 0 for task in tasks)
    
    @pytest.mark.asyncio
    async def test_prioritize_tasks(self, planner):
        """æµ‹è¯•ä»»åŠ¡ä¼˜å…ˆçº§æ’åº"""
        tasks = [
            Task("1", "Low priority", 1, "pending", {}, datetime.now(), datetime.now()),
            Task("2", "High priority", 10, "pending", {}, datetime.now(), datetime.now()),
            Task("3", "Medium priority", 5, "pending", {}, datetime.now(), datetime.now()),
        ]
        
        prioritized = await planner.prioritize_tasks(tasks)
        
        assert prioritized[0].priority == 10
        assert prioritized[1].priority == 5
        assert prioritized[2].priority == 1

class TestMemoryManager:
    """è®°å¿†ç®¡ç†å™¨æµ‹è¯•"""
    
    @pytest.fixture
    def memory_manager(self):
        return MemoryManager()
    
    @pytest.mark.asyncio
    async def test_store_retrieve_short_term(self, memory_manager):
        """æµ‹è¯•çŸ­æœŸè®°å¿†å­˜å‚¨å’Œæ£€ç´¢"""
        await memory_manager.store_short_term("test_key", "test_value")
        
        context = await memory_manager.retrieve_context("test")
        assert "test_key" in context["short_term"]
        assert context["short_term"]["test_key"]["value"] == "test_value"
    
    @pytest.mark.asyncio
    async def test_memory_cleanup(self, memory_manager):
        """æµ‹è¯•è®°å¿†æ¸…ç†"""
        # æ·»åŠ è¶…è¿‡é™åˆ¶çš„è®°å¿†
        for i in range(1100):
            await memory_manager.store_short_term(f"key_{i}", f"value_{i}")
        
        # æ£€æŸ¥æ˜¯å¦æ¸…ç†åˆ°åˆç†èŒƒå›´
        assert len(memory_manager.memory.short_term) <= 1000

class TestAgent:
    """æ™ºèƒ½ä½“æµ‹è¯•"""
    
    @pytest.fixture
    def agent(self):
        return Agent("TestAgent")
    
    @pytest.mark.asyncio
    async def test_process_input(self, agent):
        """æµ‹è¯•è¾“å…¥å¤„ç†"""
        # Mockå·¥å…·ç®¡ç†å™¨
        agent.tool_manager.execute_tool = AsyncMock(return_value="test_result")
        
        result = await agent.process_input("Test input")
        
        assert result is not None
        assert "test_result" in result or "Error" in result
    
    @pytest.mark.asyncio
    async def test_security_validation(self, agent):
        """æµ‹è¯•å®‰å…¨éªŒè¯"""
        # æµ‹è¯•æ¶æ„è¾“å…¥
        malicious_input = "<script>alert('xss')</script>"
        result = await agent.process_input(malicious_input)
        
        assert "Input validation failed" in result
```

### ğŸ§ª 2. é›†æˆæµ‹è¯•

**ç¼–å†™é›†æˆæµ‹è¯•éªŒè¯æ¨¡å—åä½œï¼š**

```python
import pytest
import asyncio
from agent_template import Agent, CalculatorTool, WebSearchTool

class TestAgentIntegration:
    """æ™ºèƒ½ä½“é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    async def agent_with_tools(self):
        """åˆ›å»ºå¸¦å·¥å…·çš„æ™ºèƒ½ä½“"""
        agent = Agent("IntegrationTestAgent")
        
        # æ³¨å†Œå·¥å…·
        calculator = CalculatorTool()
        web_search = WebSearchTool()
        agent.tool_manager.register_tool(calculator)
        agent.tool_manager.register_tool(web_search)
        
        return agent
    
    @pytest.mark.asyncio
    async def test_end_to_end_workflow(self, agent_with_tools):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        # æ¨¡æ‹Ÿå®Œæ•´çš„æ™ºèƒ½ä½“å·¥ä½œæµ
        input_data = "Calculate 2+2 and search for AI agents"
        
        result = await agent_with_tools.process_input(input_data)
        
        # éªŒè¯ç»“æœ
        assert result is not None
        assert len(result) > 0
        
        # éªŒè¯è®°å¿†æ˜¯å¦è¢«æ­£ç¡®å­˜å‚¨
        context = await agent_with_tools.memory_manager.retrieve_context("calculate")
        assert len(context["short_term"]) > 0 or len(context["long_term"]) > 0
    
    @pytest.mark.asyncio
    async def test_multi_agent_coordination(self):
        """æµ‹è¯•å¤šæ™ºèƒ½ä½“åè°ƒ"""
        from agent_template import MultiAgentCoordinator
        
        coordinator = MultiAgentCoordinator()
        
        # åˆ›å»ºå¤šä¸ªæ™ºèƒ½ä½“
        agent1 = Agent("Agent1")
        agent2 = Agent("Agent2")
        
        coordinator.register_agent("agent1", agent1)
        coordinator.register_agent("agent2", agent2)
        
        # æµ‹è¯•ä»»åŠ¡åè°ƒ
        task = "Analyze market data"
        agent_ids = ["agent1", "agent2"]
        
        results = await coordinator.coordinate_task(task, agent_ids)
        
        assert len(results) == 2
        assert "agent1" in results
        assert "agent2" in results
```

### ğŸ§ª 3. æ€§èƒ½æµ‹è¯•

**ç¼–å†™æ€§èƒ½æµ‹è¯•éªŒè¯ç³»ç»Ÿæ€§èƒ½ï¼š**

```python
import pytest
import asyncio
import time
from agent_template import Agent

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture
    def agent(self):
        return Agent("PerformanceTestAgent")
    
    @pytest.mark.asyncio
    async def test_response_time(self, agent):
        """æµ‹è¯•å“åº”æ—¶é—´"""
        start_time = time.time()
        
        result = await agent.process_input("Simple test input")
        
        end_time = time.time()
        response_time = end_time - start_time
        
        # å“åº”æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        assert response_time < 5.0  # 5ç§’å†…å®Œæˆ
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self, agent):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†"""
        async def make_request(request_id: int):
            return await agent.process_input(f"Request {request_id}")
        
        # å¹¶å‘å‘é€10ä¸ªè¯·æ±‚
        tasks = [make_request(i) for i in range(10)]
        start_time = time.time()
        
        results = await asyncio.gather(*tasks)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # éªŒè¯æ‰€æœ‰è¯·æ±‚éƒ½æˆåŠŸ
        assert len(results) == 10
        assert all(result is not None for result in results)
        
        # å¹¶å‘å¤„ç†åº”è¯¥æ¯”ä¸²è¡Œå¤„ç†å¿«
        assert total_time < 10.0  # 10ä¸ªè¯·æ±‚åœ¨10ç§’å†…å®Œæˆ
    
    @pytest.mark.asyncio
    async def test_memory_usage(self, agent):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss
        
        # æ‰§è¡Œå¤§é‡æ“ä½œ
        for i in range(100):
            await agent.process_input(f"Memory test {i}")
        
        final_memory = process.memory_info().rss
        memory_increase = final_memory - initial_memory
        
        # å†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        assert memory_increase < 100 * 1024 * 1024  # 100MBä»¥å†…
```

---

## ç›‘æ§å‘Šè­¦ä½“ç³»

### ğŸ“Š 1. æŒ‡æ ‡æ”¶é›†

**ä½¿ç”¨Prometheusæ”¶é›†å…³é”®æŒ‡æ ‡ï¼š**

```python
from prometheus_client import Counter, Histogram, Gauge, start_http_server
import time

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
agent_requests_total = Counter('agent_requests_total', 'Total agent requests', ['agent_name', 'status'])
agent_request_duration = Histogram('agent_request_duration_seconds', 'Agent request duration')
agent_memory_usage = Gauge('agent_memory_usage_bytes', 'Agent memory usage')
agent_active_tasks = Gauge('agent_active_tasks', 'Number of active tasks')
agent_tool_executions = Counter('agent_tool_executions_total', 'Tool executions', ['tool_name', 'status'])

class AgentMonitor:
    """æ™ºèƒ½ä½“ç›‘æ§å™¨"""
    
    def __init__(self, agent_name: str):
        self.agent_name = agent_name
    
    def record_request(self, duration: float, status: str = "success"):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        agent_requests_total.labels(
            agent_name=self.agent_name,
            status=status
        ).inc()
        agent_request_duration.observe(duration)
    
    def update_memory_usage(self, usage: int):
        """æ›´æ–°å†…å­˜ä½¿ç”¨é‡"""
        agent_memory_usage.set(usage)
    
    def update_active_tasks(self, count: int):
        """æ›´æ–°æ´»è·ƒä»»åŠ¡æ•°"""
        agent_active_tasks.set(count)
    
    def record_tool_execution(self, tool_name: str, status: str = "success"):
        """è®°å½•å·¥å…·æ‰§è¡Œ"""
        agent_tool_executions.labels(
            tool_name=tool_name,
            status=status
        ).inc()

# å¯åŠ¨ç›‘æ§æœåŠ¡å™¨
def start_monitoring(port: int = 9090):
    """å¯åŠ¨ç›‘æ§æœåŠ¡å™¨"""
    start_http_server(port)
    print(f"Monitoring server started on port {port}")
```

### ğŸ“Š 2. æ—¥å¿—èšåˆ

**ä½¿ç”¨ELK Stackè¿›è¡Œæ—¥å¿—èšåˆï¼š**

```python
import logging
import json
from datetime import datetime
from elasticsearch import Elasticsearch

class ElasticsearchHandler(logging.Handler):
    """Elasticsearchæ—¥å¿—å¤„ç†å™¨"""
    
    def __init__(self, es_client: Elasticsearch, index_name: str):
        super().__init__()
        self.es_client = es_client
        self.index_name = index_name
    
    def emit(self, record):
        """å‘é€æ—¥å¿—åˆ°Elasticsearch"""
        try:
            log_entry = {
                'timestamp': datetime.utcnow().isoformat(),
                'level': record.levelname,
                'message': record.getMessage(),
                'module': record.module,
                'function': record.funcName,
                'line': record.lineno,
            }
            
            # æ·»åŠ é¢å¤–å­—æ®µ
            if hasattr(record, 'agent_name'):
                log_entry['agent_name'] = record.agent_name
            if hasattr(record, 'task_id'):
                log_entry['task_id'] = record.task_id
            if hasattr(record, 'user_id'):
                log_entry['user_id'] = record.user_id
            
            # å‘é€åˆ°Elasticsearch
            self.es_client.index(
                index=self.index_name,
                body=log_entry
            )
        except Exception as e:
            print(f"Failed to send log to Elasticsearch: {e}")

# é…ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    es_client = Elasticsearch(['localhost:9200'])
    
    # åˆ›å»ºElasticsearchå¤„ç†å™¨
    es_handler = ElasticsearchHandler(es_client, 'agent-logs')
    es_handler.setLevel(logging.INFO)
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    es_handler.setFormatter(formatter)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    root_logger = logging.getLogger()
    root_logger.addHandler(es_handler)
    root_logger.setLevel(logging.INFO)
```

### ğŸ“Š 3. å‘Šè­¦è§„åˆ™

**ä½¿ç”¨Grafanaé…ç½®å‘Šè­¦è§„åˆ™ï¼š**

```yaml
# grafana-alerts.yml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-alerts
data:
  agent-alerts.yml: |
    groups:
    - name: agent-alerts
      rules:
      - alert: HighErrorRate
        expr: rate(agent_requests_total{status="error"}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"
      
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(agent_request_duration_seconds_bucket[5m])) > 5
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }} seconds"
      
      - alert: HighMemoryUsage
        expr: agent_memory_usage_bytes > 1000000000  # 1GB
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }} bytes"
      
      - alert: ToolExecutionFailure
        expr: rate(agent_tool_executions_total{status="error"}[5m]) > 0.05
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "High tool execution failure rate"
          description: "Tool execution failure rate is {{ $value }} failures per second"
```

---

## ğŸ¯ æ€»ç»“

æœ¬æœ€ä½³å®è·µæŒ‡å—åŸºäºå¯¹30+ä¸ªå¼€æºæ™ºèƒ½ä½“æ¡†æ¶çš„æ·±åº¦åˆ†æï¼Œæä¾›äº†å®Œæ•´çš„å¼€å‘ã€éƒ¨ç½²å’Œè¿ç»´æŒ‡å¯¼ã€‚é€šè¿‡éµå¾ªè¿™äº›æœ€ä½³å®è·µï¼Œæ‚¨å¯ä»¥ï¼š

1. **æé«˜å¼€å‘æ•ˆç‡**ï¼šä½¿ç”¨æ ‡å‡†åŒ–çš„å¼€å‘æ¨¡æ¿å’Œå·¥å…·é“¾
2. **ç¡®ä¿ä»£ç è´¨é‡**ï¼šé€šè¿‡å®Œå–„çš„æµ‹è¯•å’Œä»£ç å®¡æŸ¥æµç¨‹
3. **ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½**ï¼šä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹ã€ç¼“å­˜å’Œè¿æ¥æ± ç­‰æŠ€æœ¯
4. **ä¿éšœç³»ç»Ÿå®‰å…¨**ï¼šå®æ–½å¤šå±‚å®‰å…¨é˜²æŠ¤å’Œæƒé™æ§åˆ¶
5. **ç®€åŒ–éƒ¨ç½²è¿ç»´**ï¼šä½¿ç”¨å®¹å™¨åŒ–å’Œè‡ªåŠ¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ
6. **å»ºç«‹ç›‘æ§ä½“ç³»**ï¼šå®ç°å…¨é¢çš„ç›‘æ§ã€æ—¥å¿—å’Œå‘Šè­¦

é€‰æ‹©é€‚åˆæ‚¨é¡¹ç›®éœ€æ±‚çš„æœ€ä½³å®è·µï¼ŒæŒç»­ä¼˜åŒ–å’Œæ”¹è¿›æ‚¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

---

*æœ¬æŒ‡å—åŸºäºå¼€æºæ™ºèƒ½ä½“é¡¹ç›®åˆ†ææŠ¥å‘Šï¼ŒæŒç»­æ›´æ–°ä¸­ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆã€‚*
