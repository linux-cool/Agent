#!/usr/bin/env python3
"""
ç¬¬7ç«  å®‰å…¨éšç§é˜²æŠ¤ä½“ç³» - ç®€å•æµ‹è¯•è„šæœ¬
"""

import asyncio
import sys
import os

# æ·»åŠ ä»£ç è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'code'))

from threat_analysis import ThreatAnalyzer, Threat, AttackVector, RiskLevel, AgentComponent
from access_control import AccessControlSystem, Permission, ResourceType, PermissionAction, Role, User
from privacy_protection import PrivacyProtectionSystem, DataType, PrivacyLevel

async def test_threat_analysis():
    """æµ‹è¯•å¨èƒåˆ†æåŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•å¨èƒåˆ†æåŠŸèƒ½...")
    
    analyzer = ThreatAnalyzer()
    
    # æµ‹è¯•å¨èƒåˆ›å»º
    threat = Threat(
        id="TEST001",
        name="æµ‹è¯•å¨èƒ",
        description="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¨èƒ",
        attack_vector=AttackVector.PROMPT_INJECTION,
        target_component=AgentComponent.LLM,
        potential_impact="æµ‹è¯•å½±å“",
        risk_level=RiskLevel.HIGH
    )
    
    assert threat.id == "TEST001"
    assert threat.name == "æµ‹è¯•å¨èƒ"
    print("   âœ… å¨èƒåˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•ç³»ç»Ÿåˆ†æ
    architecture = {"name": "æµ‹è¯•ç³»ç»Ÿ", "components": ["LLM", "Memory"]}
    threats = await analyzer.analyze_agent_system(architecture)
    assert len(threats) > 0
    print("   âœ… ç³»ç»Ÿåˆ†ææµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•é£é™©è¯„ä¼°
    context = {"system_sensitivity": 0.8, "existing_controls_effectiveness": 0.6}
    result = await analyzer.assess_risk("TI001", context)
    assert result["success"] is True
    assert "risk_score" in result
    print("   âœ… é£é™©è¯„ä¼°æµ‹è¯•é€šè¿‡")

async def test_access_control():
    """æµ‹è¯•æƒé™æ§åˆ¶åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•æƒé™æ§åˆ¶åŠŸèƒ½...")
    
    acs = AccessControlSystem()
    
    # æµ‹è¯•æƒé™åˆ›å»º
    permission = Permission(
        resource_type=ResourceType.LLM_MODEL,
        resource_id="gpt-4",
        action=PermissionAction.READ
    )
    assert permission.resource_type == ResourceType.LLM_MODEL
    print("   âœ… æƒé™åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•è§’è‰²åˆ›å»º
    role = Role("test_role", "æµ‹è¯•è§’è‰²", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è§’è‰²")
    assert role.role_id == "test_role"
    print("   âœ… è§’è‰²åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•ç”¨æˆ·åˆ›å»º
    user = User("test_user", "æµ‹è¯•ç”¨æˆ·")
    assert user.user_id == "test_user"
    print("   âœ… ç”¨æˆ·åˆ›å»ºæµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æˆæƒ
    admin_permission = Permission(ResourceType.CONFIGURATION, None, PermissionAction.MANAGE)
    result = await acs.authorize("user_alice", admin_permission)
    assert result is True
    print("   âœ… æˆæƒæµ‹è¯•é€šè¿‡")

async def test_privacy_protection():
    """æµ‹è¯•éšç§ä¿æŠ¤åŠŸèƒ½"""
    print("ğŸ”’ æµ‹è¯•éšç§ä¿æŠ¤åŠŸèƒ½...")
    
    config = {"encryption": {"algorithm": "FERNET"}}
    privacy_system = PrivacyProtectionSystem(config)
    
    # æµ‹è¯•æ•°æ®ä¿æŠ¤
    record = await privacy_system.protect_data(
        "test@example.com",
        DataType.EMAIL,
        PrivacyLevel.HIGH
    )
    assert record.data_type == DataType.EMAIL
    assert record.original_value == "test@example.com"
    assert record.encrypted_value != ""
    assert record.anonymized_value != ""
    print("   âœ… æ•°æ®ä¿æŠ¤æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ•°æ®æ£€ç´¢
    user_data = await privacy_system.retrieve_data(record.id, ["user"])
    assert user_data == record.anonymized_value
    print("   âœ… æ•°æ®æ£€ç´¢æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•å·®åˆ†éšç§
    original_values = [100, 150, 200, 180, 120]
    noisy_values = await privacy_system.add_noise_to_statistics(original_values)
    assert len(noisy_values) == len(original_values)
    print("   âœ… å·®åˆ†éšç§æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•éšç§ç»Ÿè®¡
    stats = privacy_system.get_privacy_stats()
    assert "total_records" in stats
    print("   âœ… éšç§ç»Ÿè®¡æµ‹è¯•é€šè¿‡")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ç¬¬7ç«  å®‰å…¨éšç§é˜²æŠ¤ä½“ç³»æµ‹è¯•")
    print("=" * 50)
    
    try:
        await test_threat_analysis()
        await test_access_control()
        await test_privacy_protection()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
