# framework_demo.py
"""
ç¬¬2ç«  AIæ¡†æ¶ç ”ç©¶ä¸åº”ç”¨ - å®Œæ•´æ¼”ç¤ºç¨‹åº
å±•ç¤ºå„æ¡†æ¶çš„æ ¸å¿ƒåŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•
"""

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Any, Optional

# å¯¼å…¥å„æ¡†æ¶ç¤ºä¾‹
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from code.langchain_examples import LangChainExamples
from code.crewai_examples import CrewAIExamples
from code.autogen_examples import AutoGenExamples
from code.langgraph_examples import LangGraphExamples
from code.framework_comparison import FrameworkComparison

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FrameworkDemo:
    """æ¡†æ¶æ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.frameworks = {}
        self.demo_results = {}
        self.comparator = FrameworkComparison()
    
    async def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        logger.info("ğŸš€ å¼€å§‹ç¬¬2ç« AIæ¡†æ¶ç ”ç©¶ä¸åº”ç”¨æ¼”ç¤º")
        
        # 1. LangChainæ¼”ç¤º
        await self.demo_langchain()
        
        # 2. CrewAIæ¼”ç¤º
        await self.demo_crewai()
        
        # 3. AutoGenæ¼”ç¤º
        await self.demo_autogen()
        
        # 4. LangGraphæ¼”ç¤º
        await self.demo_langgraph()
        
        # 5. æ¡†æ¶å¯¹æ¯”åˆ†æ
        await self.demo_framework_comparison()
        
        # 6. æ€§èƒ½åŸºå‡†æµ‹è¯•
        await self.demo_performance_benchmark()
        
        # 7. é›†æˆç¤ºä¾‹
        await self.demo_integration_example()
        
        # 8. ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š
        await self.generate_demo_report()
        
        logger.info("âœ… ç¬¬2ç« æ¼”ç¤ºå®Œæˆ")
    
    async def demo_langchain(self):
        """LangChainæ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º1: LangChainæ¡†æ¶")
        
        try:
            examples = LangChainExamples()
            
            # è¿è¡ŒåŸºç¡€ç¤ºä¾‹
            basic_result = examples.basic_llm_example()
            
            # è¿è¡Œæ™ºèƒ½ä½“ç¤ºä¾‹
            agent_result = examples.agent_with_tools_example()
            
            # è¿è¡Œå‘é‡å­˜å‚¨ç¤ºä¾‹
            vector_result = examples.vector_store_example()
            
            self.demo_results["langchain"] = {
                "status": "success",
                "basic_llm": basic_result[:100] + "..." if len(basic_result) > 100 else basic_result,
                "agent_tools": agent_result[:100] + "..." if len(agent_result) > 100 else agent_result,
                "vector_store": vector_result[:100] + "..." if len(vector_result) > 100 else vector_result,
                "features": [
                    "ä¸°å¯Œçš„å·¥å…·ç”Ÿæ€",
                    "å¼ºå¤§çš„é“¾å¼è°ƒç”¨",
                    "å¤šç§è®°å¿†ç±»å‹",
                    "å‘é‡æ•°æ®åº“é›†æˆ"
                ]
            }
            
            logger.info("âœ… LangChainæ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"LangChainæ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["langchain"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_crewai(self):
        """CrewAIæ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º2: CrewAIæ¡†æ¶")
        
        try:
            examples = CrewAIExamples()
            
            # è¿è¡ŒåŸºç¡€å›¢é˜Ÿç¤ºä¾‹
            basic_crew_result = examples.basic_crew_example()
            
            # è¿è¡Œå±‚æ¬¡åŒ–å›¢é˜Ÿç¤ºä¾‹
            hierarchical_result = examples.hierarchical_crew_example()
            
            # è¿è¡Œå¹¶è¡Œå›¢é˜Ÿç¤ºä¾‹
            parallel_result = examples.parallel_crew_example()
            
            self.demo_results["crewai"] = {
                "status": "success",
                "basic_crew": basic_crew_result[:100] + "..." if len(basic_crew_result) > 100 else basic_crew_result,
                "hierarchical": hierarchical_result[:100] + "..." if len(hierarchical_result) > 100 else hierarchical_result,
                "parallel": parallel_result[:100] + "..." if len(parallel_result) > 100 else parallel_result,
                "features": [
                    "ä¸“ä¸šå¤šæ™ºèƒ½ä½“åä½œ",
                    "è§’è‰²åˆ†å·¥æ˜ç¡®",
                    "ä»»åŠ¡ä¾èµ–ç®¡ç†",
                    "å›¢é˜Ÿåä½œæœºåˆ¶"
                ]
            }
            
            logger.info("âœ… CrewAIæ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"CrewAIæ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["crewai"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_autogen(self):
        """AutoGenæ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º3: AutoGenæ¡†æ¶")
        
        try:
            examples = AutoGenExamples()
            
            # è¿è¡ŒåŸºç¡€å¯¹è¯ç¤ºä¾‹
            basic_conversation_result = examples.basic_conversation_example()
            
            # è¿è¡Œç¾¤ç»„å¯¹è¯ç¤ºä¾‹
            group_chat_result = examples.group_chat_example()
            
            # è¿è¡Œä»£ç æ‰§è¡Œç¤ºä¾‹
            code_execution_result = examples.code_execution_example()
            
            self.demo_results["autogen"] = {
                "status": "success",
                "basic_conversation": basic_conversation_result[:100] + "..." if len(basic_conversation_result) > 100 else basic_conversation_result,
                "group_chat": group_chat_result[:100] + "..." if len(group_chat_result) > 100 else group_chat_result,
                "code_execution": code_execution_result[:100] + "..." if len(code_execution_result) > 100 else code_execution_result,
                "features": [
                    "å¯¹è¯å¼å¤šæ™ºèƒ½ä½“åä½œ",
                    "ä»£ç æ‰§è¡Œèƒ½åŠ›",
                    "å¤šè½®å¯¹è¯æ”¯æŒ",
                    "åŠ¨æ€åä½œè°ƒæ•´"
                ]
            }
            
            logger.info("âœ… AutoGenæ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"AutoGenæ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["autogen"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_langgraph(self):
        """LangGraphæ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º4: LangGraphæ¡†æ¶")
        
        try:
            examples = LangGraphExamples()
            
            # è¿è¡ŒåŸºç¡€å·¥ä½œæµç¤ºä¾‹
            basic_workflow_result = examples.basic_workflow_example()
            
            # è¿è¡Œæ¡ä»¶å·¥ä½œæµç¤ºä¾‹
            conditional_result = examples.conditional_workflow_example()
            
            # è¿è¡Œå¾ªç¯å·¥ä½œæµç¤ºä¾‹
            loop_result = examples.loop_workflow_example()
            
            self.demo_results["langgraph"] = {
                "status": "success",
                "basic_workflow": basic_workflow_result[:100] + "..." if len(basic_workflow_result) > 100 else basic_workflow_result,
                "conditional": conditional_result[:100] + "..." if len(conditional_result) > 100 else conditional_result,
                "loop": loop_result[:100] + "..." if len(loop_result) > 100 else loop_result,
                "features": [
                    "çŠ¶æ€æœºå·¥ä½œæµ",
                    "æ¡ä»¶åˆ†æ”¯å¤„ç†",
                    "å¾ªç¯æ§åˆ¶",
                    "å¯è§†åŒ–å·¥ä½œæµ"
                ]
            }
            
            logger.info("âœ… LangGraphæ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"LangGraphæ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["langgraph"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_framework_comparison(self):
        """æ¡†æ¶å¯¹æ¯”æ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º5: æ¡†æ¶å¯¹æ¯”åˆ†æ")
        
        try:
            # å¯¹æ¯”ä¸»è¦æ¡†æ¶
            framework_names = ["langchain", "crewai", "autogen", "langgraph"]
            comparison_data = self.comparator.compare_frameworks(framework_names)
            
            # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
            report = self.comparator.generate_comparison_report(framework_names)
            
            # åˆ†æè¶‹åŠ¿
            trends = self.comparator.analyze_trends()
            
            self.demo_results["framework_comparison"] = {
                "status": "success",
                "frameworks_compared": len(comparison_data),
                "report_length": len(report),
                "trends_analyzed": len(trends["emerging_trends"]),
                "comparison_summary": {
                    "langchain": {
                        "github_stars": comparison_data["langchain"]["github_stars"],
                        "learning_curve": comparison_data["langchain"]["learning_curve"],
                        "tool_ecosystem": comparison_data["langchain"]["tool_ecosystem"]
                    },
                    "crewai": {
                        "github_stars": comparison_data["crewai"]["github_stars"],
                        "learning_curve": comparison_data["crewai"]["learning_curve"],
                        "multi_agent_support": comparison_data["crewai"]["multi_agent_support"]
                    },
                    "autogen": {
                        "github_stars": comparison_data["autogen"]["github_stars"],
                        "learning_curve": comparison_data["autogen"]["learning_curve"],
                        "multi_agent_support": comparison_data["autogen"]["multi_agent_support"]
                    },
                    "langgraph": {
                        "github_stars": comparison_data["langgraph"]["github_stars"],
                        "learning_curve": comparison_data["langgraph"]["learning_curve"],
                        "workflow_management": comparison_data["langgraph"]["workflow_management"]
                    }
                }
            }
            
            logger.info("âœ… æ¡†æ¶å¯¹æ¯”æ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¡†æ¶å¯¹æ¯”æ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["framework_comparison"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_performance_benchmark(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º6: æ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        try:
            # å®šä¹‰æµ‹è¯•ç”¨ä¾‹
            test_cases = ["basic_task", "complex_workflow", "multi_agent_collaboration"]
            framework_names = ["langchain", "crewai", "autogen", "langgraph"]
            
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            benchmark_results = self.comparator.benchmark_frameworks(framework_names, test_cases)
            
            # åˆ†ææ€§èƒ½æ•°æ®
            performance_summary = {}
            for framework_name, results in benchmark_results.items():
                performance_summary[framework_name] = {
                    "overall_score": results["overall_score"],
                    "test_count": len(results["test_results"]),
                    "average_execution_time": sum(
                        test["execution_time"] for test in results["test_results"].values()
                    ) / len(results["test_results"])
                }
            
            self.demo_results["performance_benchmark"] = {
                "status": "success",
                "frameworks_tested": len(benchmark_results),
                "test_cases": len(test_cases),
                "performance_summary": performance_summary,
                "ranking": sorted(
                    performance_summary.items(),
                    key=lambda x: x[1]["overall_score"],
                    reverse=True
                )
            }
            
            logger.info("âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["performance_benchmark"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def demo_integration_example(self):
        """é›†æˆç¤ºä¾‹æ¼”ç¤º"""
        logger.info("ğŸ“‹ æ¼”ç¤º7: å¤šæ¡†æ¶é›†æˆç¤ºä¾‹")
        
        try:
            # æ¨¡æ‹Ÿå¤šæ¡†æ¶é›†æˆåœºæ™¯
            integration_scenario = {
                "name": "æ™ºèƒ½å®¢æœç³»ç»Ÿ",
                "description": "ä½¿ç”¨å¤šä¸ªæ¡†æ¶æ„å»ºçš„æ™ºèƒ½å®¢æœç³»ç»Ÿ",
                "components": {
                    "langchain": "å¤„ç†ç”¨æˆ·æŸ¥è¯¢å’Œå·¥å…·è°ƒç”¨",
                    "crewai": "å¤šæ™ºèƒ½ä½“åä½œå¤„ç†å¤æ‚é—®é¢˜",
                    "autogen": "å¯¹è¯ç®¡ç†å’Œä¸Šä¸‹æ–‡ä¿æŒ",
                    "langgraph": "å·¥ä½œæµç®¡ç†å’ŒçŠ¶æ€æ§åˆ¶"
                },
                "workflow": [
                    "ç”¨æˆ·è¾“å…¥å¤„ç† (LangChain)",
                    "é—®é¢˜åˆ†ç±»å’Œè·¯ç”± (CrewAI)",
                    "å¯¹è¯ç®¡ç† (AutoGen)",
                    "å·¥ä½œæµæ§åˆ¶ (LangGraph)"
                ]
            }
            
            # æ¨¡æ‹Ÿé›†æˆæµ‹è¯•
            integration_results = {
                "components_integrated": len(integration_scenario["components"]),
                "workflow_steps": len(integration_scenario["workflow"]),
                "integration_success": True,
                "performance_metrics": {
                    "response_time": 1.2,  # seconds
                    "throughput": 50,  # requests per minute
                    "error_rate": 0.01,  # 1%
                    "availability": 0.999  # 99.9%
                }
            }
            
            self.demo_results["integration_example"] = {
                "status": "success",
                "scenario": integration_scenario,
                "results": integration_results,
                "best_practices": [
                    "ä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼",
                    "å®æ–½é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶",
                    "ç›‘æ§å„ç»„ä»¶æ€§èƒ½",
                    "å®ç°ä¼˜é›…é™çº§"
                ]
            }
            
            logger.info("âœ… é›†æˆç¤ºä¾‹æ¼”ç¤ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"é›†æˆç¤ºä¾‹æ¼”ç¤ºå¤±è´¥: {e}")
            self.demo_results["integration_example"] = {
                "status": "error",
                "error": str(e)
            }
    
    async def generate_demo_report(self):
        """ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š"""
        logger.info("ğŸ“‹ ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š")
        
        report = {
            "demo_info": {
                "title": "ç¬¬2ç«  AIæ¡†æ¶ç ”ç©¶ä¸åº”ç”¨æ¼”ç¤ºæŠ¥å‘Š",
                "timestamp": datetime.now().isoformat(),
                "total_demos": len(self.demo_results)
            },
            "results": self.demo_results,
            "summary": {
                "frameworks_demoed": len([r for r in self.demo_results.values() if r["status"] == "success"]),
                "total_features_tested": sum(
                    len(r.get("features", [])) for r in self.demo_results.values() 
                    if r["status"] == "success" and "features" in r
                ),
                "performance_benchmarks": len(
                    self.demo_results.get("performance_benchmark", {}).get("performance_summary", {})
                ),
                "integration_scenarios": 1
            },
            "recommendations": {
                "general_ai_app": "LangChain - ç”Ÿæ€æœ€ä¸°å¯Œ",
                "multi_agent_collaboration": "CrewAI - ä¸“ä¸šå¤šæ™ºèƒ½ä½“æ¡†æ¶",
                "workflow_automation": "LangGraph - å¼ºå¤§çš„çŠ¶æ€æœºæ”¯æŒ",
                "conversational_ai": "AutoGen - å¯¹è¯å¼åä½œ"
            }
        }
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_filename = f"chapter2_demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ“„ æ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
        
        # æ‰“å°æ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š ç¬¬2ç« æ¼”ç¤ºæŠ¥å‘Šæ‘˜è¦")
        print("="*60)
        print(f"æ¼”ç¤ºæ—¶é—´: {report['demo_info']['timestamp']}")
        print(f"æ¼”ç¤ºé¡¹ç›®æ•°: {report['demo_info']['total_demos']}")
        print(f"æ¡†æ¶æ¼”ç¤ºæ•°: {report['summary']['frameworks_demoed']}")
        print(f"åŠŸèƒ½æµ‹è¯•æ•°: {report['summary']['total_features_tested']}")
        print(f"æ€§èƒ½åŸºå‡†æ•°: {report['summary']['performance_benchmarks']}")
        print(f"é›†æˆåœºæ™¯æ•°: {report['summary']['integration_scenarios']}")
        
        print("\nğŸ¯ æ¡†æ¶æ¨è:")
        for use_case, recommendation in report['recommendations'].items():
            print(f"- {use_case}: {recommendation}")
        
        print("="*60)
        
        return report

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– ç¬¬2ç«  AIæ¡†æ¶ç ”ç©¶ä¸åº”ç”¨ - å®Œæ•´æ¼”ç¤º")
    print("="*60)
    
    demo = FrameworkDemo()
    await demo.run_complete_demo()
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœã€‚")

if __name__ == "__main__":
    asyncio.run(main())
